# Day 3 æ¨¡å—è®¾è®¡è§„èŒƒ

**æ—¥æœŸ**: 2025-01-XX
**ç›®æ ‡**: å®ç°ResponseGeneratorã€ConversationalInterfaceã€CLI

---

## ä¸€ã€æ€»è§ˆ

Day 3 å®Œæˆå¯¹è¯ç³»ç»Ÿçš„æœ€å3ä¸ªæ¨¡å—ï¼Œå®ç°ä»æŸ¥è¯¢åˆ°å“åº”çš„å®Œæ•´é—­ç¯ï¼š

- **ResponseGenerator**: ç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­” + å¼•ç”¨æ¥æº
- **ConversationalInterface**: ä¸»æ§åˆ¶å™¨ï¼Œåè°ƒæ‰€æœ‰æ¨¡å—
- **CLI**: å‘½ä»¤è¡Œäº¤äº’ç•Œé¢

å®Œæˆåæ•´ä¸ªå¯¹è¯ç³»ç»Ÿå¯ç‹¬ç«‹è¿è¡Œã€‚

---

## äºŒã€ResponseGenerator è®¾è®¡

### 2.1 èŒè´£

å°†æ£€ç´¢ç»“æœè½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€å›ç­”ï¼Œæ·»åŠ æ¥æºå¼•ç”¨å’Œæ—¶é—´æˆ³ã€‚

### 2.2 æ ¸å¿ƒåŠŸèƒ½

```python
class ResponseGenerator:
    """å“åº”ç”Ÿæˆå™¨ - å°†æ£€ç´¢ç»“æœè½¬ä¸ºè‡ªç„¶è¯­è¨€"""

    def __init__(self, llm_client):
        self.llm_client = llm_client
        self.answer_prompt = self._load_answer_prompt()

    def generate(
        self,
        query: str,
        query_result: QueryResult,
        retrieval_results: List[RetrievalResult],
        context: Optional[ConversationContext] = None
    ) -> Response:
        """ç”Ÿæˆæœ€ç»ˆå›ç­”"""
```

### 2.3 Responseç»“æ„

```python
@dataclass
class Response:
    """å¯¹è¯å“åº”"""
    answer: str                      # è‡ªç„¶è¯­è¨€å›ç­”
    sources: List[Source]            # å¼•ç”¨æ¥æº
    confidence: float                # ç½®ä¿¡åº¦
    retrieved_count: int             # æ£€ç´¢åˆ°çš„å†…å®¹æ•°é‡
    response_time_ms: float          # å“åº”æ—¶é—´
    metadata: Dict                   # é¢å¤–ä¿¡æ¯
```

### 2.4 ç”Ÿæˆç­–ç•¥

**æ ¹æ®Intenté€‰æ‹©ä¸åŒçš„ç”Ÿæˆæ¨¡æ¿**:

| Intent | ç”Ÿæˆç­–ç•¥ |
|--------|---------|
| SEARCH_SEMANTIC | ç»¼åˆå¤šä¸ªatomsï¼Œç”Ÿæˆè¿è´¯å›ç­” |
| SEARCH_ENTITY | ä»‹ç»å®ä½“ï¼Œåˆ—å‡ºå…³é”®ä¿¡æ¯ |
| SEARCH_RELATION | è§£é‡Šå…³ç³»ï¼Œå¼•ç”¨graphæ•°æ® |
| SUMMARY | æå–segmentsï¼Œç”Ÿæˆæ‘˜è¦ |
| RECOMMEND_CLIP | åˆ—å‡ºæ¨èç‰‡æ®µï¼Œè¯´æ˜ç†ç”± |

### 2.5 å¼•ç”¨æ ¼å¼

```python
@dataclass
class Source:
    """å›ç­”æ¥æº"""
    item_id: str                     # atom_id/segment_id
    item_type: str                   # 'atom'/'segment'
    start_time: float                # å¼€å§‹æ—¶é—´(ç§’)
    end_time: float                  # ç»“æŸæ—¶é—´(ç§’)
    excerpt: str                     # å†…å®¹æ‘˜å½•
    relevance_score: float           # ç›¸å…³åº¦
```

åœ¨å›ç­”ä¸­æ·»åŠ æ ‡è®°ï¼š`[Source 1: 00:15-00:45]`

### 2.6 å®Œæ•´å®ç°

```python
# -*- coding: utf-8 -*-
"""Response Generator - Natural Language Answer Generation"""

import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class Source:
    """Answer source reference"""
    item_id: str
    item_type: str
    start_time: float
    end_time: float
    excerpt: str
    relevance_score: float

@dataclass
class Response:
    """Conversation response"""
    answer: str
    sources: List[Source]
    confidence: float
    retrieved_count: int
    response_time_ms: float
    metadata: Dict

class ResponseGenerator:
    """Natural language response generator"""

    def __init__(self, llm_client):
        self.llm_client = llm_client
        self.answer_prompt = self._load_answer_prompt()
        logger.info("ResponseGenerator initialized")

    def generate(
        self,
        query: str,
        query_result,
        retrieval_results: List,
        context = None
    ) -> Response:
        """Generate final answer"""
        start_time = time.time()

        # Build prompt
        prompt = self._build_prompt(query, query_result, retrieval_results, context)

        # Call LLM
        try:
            answer_text = self.llm_client.call(prompt, max_tokens=800, temperature=0.3)
            confidence = 0.8
        except Exception as e:
            logger.error(f"LLM call failed: {e}")
            answer_text = self._generate_fallback_answer(query_result, retrieval_results)
            confidence = 0.4

        # Extract sources
        sources = self._extract_sources(retrieval_results)

        # Build response
        response = Response(
            answer=answer_text,
            sources=sources,
            confidence=confidence,
            retrieved_count=len(retrieval_results),
            response_time_ms=(time.time() - start_time) * 1000,
            metadata={'intent': query_result.intent.value if hasattr(query_result.intent, 'value') else str(query_result.intent)}
        )

        logger.info(f"Generated response in {response.response_time_ms:.0f}ms")
        return response

    def _build_prompt(self, query: str, query_result, retrieval_results: List, context) -> str:
        """Build LLM prompt"""
        intent_str = query_result.intent.value if hasattr(query_result.intent, 'value') else str(query_result.intent)

        # Format retrieved content
        content_items = []
        for i, result in enumerate(retrieval_results[:5], 1):
            item = result.content
            excerpt = self._get_excerpt(item)
            time_str = self._format_time(item.get('start_time', 0), item.get('end_time', 0))
            content_items.append(f"[{i}] {time_str}\n{excerpt}")

        content_str = "\n\n".join(content_items)

        # Build prompt
        prompt = f"""You are answering questions about a video based on retrieved content.

User Query: {query}
Query Intent: {intent_str}

Retrieved Content:
{content_str}

Instructions:
- Answer the question directly based on the retrieved content
- Cite sources using [Source N: MM:SS-MM:SS] format
- If content is insufficient, say so honestly
- Keep answer concise (2-3 paragraphs max)

Answer:"""

        return prompt

    def _generate_fallback_answer(self, query_result, retrieval_results: List) -> str:
        """Generate fallback answer when LLM fails"""
        if not retrieval_results:
            return "I couldn't find relevant information to answer your question."

        # Simple concatenation
        excerpts = []
        for result in retrieval_results[:3]:
            excerpt = self._get_excerpt(result.content)
            excerpts.append(excerpt)

        return " ".join(excerpts)

    def _extract_sources(self, retrieval_results: List) -> List[Source]:
        """Extract sources from retrieval results"""
        sources = []

        for result in retrieval_results[:5]:
            item = result.content
            sources.append(Source(
                item_id=result.item_id,
                item_type=result.item_type,
                start_time=item.get('start_time', 0.0),
                end_time=item.get('end_time', 0.0),
                excerpt=self._get_excerpt(item),
                relevance_score=result.score
            ))

        return sources

    def _get_excerpt(self, item: Dict) -> str:
        """Get text excerpt from item"""
        if 'text' in item:
            return item['text'][:200]
        elif 'content' in item:
            return item['content'][:200]
        elif 'summary' in item:
            return item['summary'][:200]
        else:
            return str(item)[:200]

    def _format_time(self, start: float, end: float) -> str:
        """Format timestamp"""
        def seconds_to_mmss(seconds):
            mins = int(seconds // 60)
            secs = int(seconds % 60)
            return f"{mins:02d}:{secs:02d}"

        if start == 0 and end == 0:
            return "[Time N/A]"

        return f"[{seconds_to_mmss(start)}-{seconds_to_mmss(end)}]"

    def _load_answer_prompt(self) -> str:
        """Load answer generation prompt"""
        return ""  # Prompt built dynamically in _build_prompt

    def __repr__(self) -> str:
        return f"ResponseGenerator(llm={self.llm_client.provider})"
```

**ä»£ç é‡**: ~250è¡Œ

---

## ä¸‰ã€ConversationalInterface è®¾è®¡

### 3.1 èŒè´£

ä¸»æ§åˆ¶å™¨ï¼Œåè°ƒæ‰€æœ‰æ¨¡å—å®Œæˆä¸€æ¬¡å¯¹è¯äº¤äº’ã€‚

### 3.2 å®Œæ•´æµç¨‹

```
ç”¨æˆ·è¾“å…¥ query
    â†“
1. ContextManager: è·å–ä¼šè¯ä¸Šä¸‹æ–‡
    â†“
2. QueryUnderstanding: è§£ææ„å›¾ â†’ QueryResult
    â†“
3. HybridRetriever: æ£€ç´¢å†…å®¹ â†’ RetrievalResult[]
    â†“
4. ResponseGenerator: ç”Ÿæˆå›ç­” â†’ Response
    â†“
5. ContextManager: æ›´æ–°ä¸Šä¸‹æ–‡
    â†“
è¿”å› Response
```

### 3.3 æ ¸å¿ƒæ¥å£

```python
class ConversationalInterface:
    """å¯¹è¯ç³»ç»Ÿä¸»æ§åˆ¶å™¨"""

    def __init__(
        self,
        data_loader: DataLoader,
        context_manager: ContextManager,
        query_engine: QueryUnderstanding,
        retriever: HybridRetriever,
        response_gen: ResponseGenerator
    ):
        # åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—

    def ask(
        self,
        query: str,
        session_id: Optional[str] = None,
        mode: SessionMode = SessionMode.EXPLORATION
    ) -> Response:
        """å¤„ç†ä¸€æ¬¡å¯¹è¯äº¤äº’"""
```

### 3.4 å®Œæ•´å®ç°

```python
# -*- coding: utf-8 -*-
"""Conversational Interface - Main Orchestration"""

import logging
import time
from typing import Optional

logger = logging.getLogger(__name__)

class ConversationalInterface:
    """Main conversational interface orchestrator"""

    def __init__(
        self,
        data_loader,
        context_manager,
        query_engine,
        retriever,
        response_gen
    ):
        self.data_loader = data_loader
        self.context_manager = context_manager
        self.query_engine = query_engine
        self.retriever = retriever
        self.response_gen = response_gen
        logger.info("ConversationalInterface initialized")

    def ask(
        self,
        query: str,
        session_id: Optional[str] = None,
        mode = None
    ):
        """Process one conversation turn"""
        start_time = time.time()

        try:
            # Step 1: Get or create session
            if not session_id:
                from .context_manager import SessionMode
                mode = mode or SessionMode.EXPLORATION
                session_id = self.context_manager.create_session(
                    video_id="default_video",
                    mode=mode
                )
                logger.info(f"Created new session: {session_id}")

            # Step 2: Parse query
            logger.debug("Parsing query...")
            query_result = self.query_engine.parse(query, session_id)
            logger.info(f"Intent: {query_result.intent.value if hasattr(query_result.intent, 'value') else query_result.intent}")

            # Step 3: Retrieve content
            logger.debug("Retrieving content...")
            retrieval_results = self.retriever.retrieve(query_result, top_k=5)
            logger.info(f"Retrieved {len(retrieval_results)} results")

            # Step 4: Generate response
            logger.debug("Generating response...")
            context = self.context_manager.get_session(session_id)
            response = self.response_gen.generate(
                query, query_result, retrieval_results, context
            )

            # Step 5: Update context
            self.context_manager.add_turn(session_id, "user", query)
            self.context_manager.add_turn(session_id, "assistant", response.answer)
            self.context_manager.update_focus_entities(session_id, query_result.entities)

            # Add session_id to metadata
            response.metadata['session_id'] = session_id

            elapsed = (time.time() - start_time) * 1000
            logger.info(f"Total time: {elapsed:.0f}ms")

            return response

        except Exception as e:
            logger.error(f"Conversation failed: {e}", exc_info=True)
            raise

    def get_session_history(self, session_id: str):
        """Get session conversation history"""
        session = self.context_manager.get_session(session_id)
        if not session:
            return []
        return session.history

    def list_sessions(self):
        """List all active sessions"""
        return list(self.context_manager.sessions.keys())

    def __repr__(self) -> str:
        return "ConversationalInterface(modules=5)"
```

**ä»£ç é‡**: ~150è¡Œ

---

## å››ã€CLI è®¾è®¡

### 4.1 èŒè´£

æä¾›å‘½ä»¤è¡Œäº¤äº’ç•Œé¢ï¼Œæ–¹ä¾¿æµ‹è¯•å’Œæ¼”ç¤ºã€‚

### 4.2 åŠŸèƒ½éœ€æ±‚

1. **äº¤äº’æ¨¡å¼**: å¾ªç¯æ¥æ”¶ç”¨æˆ·è¾“å…¥
2. **å‘½ä»¤æ”¯æŒ**:
   - `/help`: æ˜¾ç¤ºå¸®åŠ©
   - `/mode <mode>`: åˆ‡æ¢æ¨¡å¼
   - `/history`: æŸ¥çœ‹å†å²
   - `/clear`: æ¸…ç©ºä¼šè¯
   - `/exit`: é€€å‡º
3. **æ ¼å¼åŒ–è¾“å‡º**: ç¾åŒ–æ˜¾ç¤ºå›ç­”å’Œæ¥æº
4. **é”™è¯¯å¤„ç†**: å‹å¥½çš„é”™è¯¯æç¤º

### 4.3 ç•Œé¢è®¾è®¡

```
=================================================
ğŸ“¹ Video Understanding - Conversational Interface
=================================================

Video: test_video.mp4
Mode: EXPLORATION

> What is this video about?

[Thinking...]

Answer:
This video discusses the history of the Golden Triangle
region in Myanmar, focusing on the era of the "Twin Heroes"...
[Source 1: 00:15-01:23] [Source 2: 02:45-03:10]

Response time: 1.2s | Confidence: 0.85

> /history

Conversation History:
1. [User] What is this video about?
2. [Assistant] This video discusses...

>
```

### 4.4 å®Œæ•´å®ç°

```python
# -*- coding: utf-8 -*-
"""CLI - Command Line Interface for Conversational System"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import logging
from conversational import (
    DataLoader, ContextManager, QueryUnderstanding,
    HybridRetriever, ConversationalInterface, SessionMode
)
from conversational.response_generator import ResponseGenerator
from core.llm_client import LLMClient

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class CLI:
    """Command-line interface for conversational system"""

    def __init__(self, data_path: str, llm_provider: str = "openai"):
        """Initialize CLI"""
        print("Initializing conversational system...")

        # Initialize all components
        self.data_loader = DataLoader(data_path)
        self.context_manager = ContextManager()

        llm_client = LLMClient(provider=llm_provider, model="gpt-4o-mini")
        self.query_engine = QueryUnderstanding(llm_client, self.context_manager)
        self.retriever = HybridRetriever(self.data_loader)
        self.response_gen = ResponseGenerator(llm_client)

        self.interface = ConversationalInterface(
            self.data_loader,
            self.context_manager,
            self.query_engine,
            self.retriever,
            self.response_gen
        )

        self.session_id = None
        self.mode = SessionMode.EXPLORATION

        print("System ready!\n")

    def run(self):
        """Run interactive CLI"""
        self.print_banner()

        while True:
            try:
                query = input("\n> ").strip()

                if not query:
                    continue

                # Handle commands
                if query.startswith('/'):
                    self.handle_command(query)
                    continue

                # Process query
                print("\n[Thinking...]")
                response = self.interface.ask(query, self.session_id, self.mode)

                # Update session_id
                if not self.session_id:
                    self.session_id = response.metadata.get('session_id')

                # Display response
                self.display_response(response)

            except KeyboardInterrupt:
                print("\n\nGoodbye!")
                break
            except Exception as e:
                print(f"\n[ERROR] {e}")
                logger.error(f"Error: {e}", exc_info=True)

    def print_banner(self):
        """Print welcome banner"""
        print("=" * 60)
        print("Video Understanding - Conversational Interface")
        print("=" * 60)
        print(f"\nMode: {self.mode.value if hasattr(self.mode, 'value') else self.mode}")
        print("\nCommands: /help /mode /history /clear /exit")
        print("-" * 60)

    def display_response(self, response):
        """Display formatted response"""
        print(f"\nAnswer:\n{response.answer}\n")

        if response.sources:
            print("Sources:")
            for i, source in enumerate(response.sources[:3], 1):
                time_str = self.format_time(source.start_time, source.end_time)
                print(f"  [{i}] {time_str} - {source.item_type} ({source.relevance_score:.2f})")

        print(f"\nResponse time: {response.response_time_ms/1000:.1f}s | " +
              f"Confidence: {response.confidence:.2f} | " +
              f"Retrieved: {response.retrieved_count} items")

    def handle_command(self, command: str):
        """Handle CLI commands"""
        parts = command.split()
        cmd = parts[0].lower()

        if cmd == '/help':
            self.print_help()
        elif cmd == '/mode':
            if len(parts) > 1:
                self.change_mode(parts[1])
            else:
                print(f"Current mode: {self.mode.value if hasattr(self.mode, 'value') else self.mode}")
        elif cmd == '/history':
            self.show_history()
        elif cmd == '/clear':
            self.clear_session()
        elif cmd == '/exit':
            print("Goodbye!")
            sys.exit(0)
        else:
            print(f"Unknown command: {cmd}. Type /help for help.")

    def print_help(self):
        """Print help information"""
        print("""
Available Commands:
  /help              Show this help message
  /mode <mode>       Change conversation mode (exploration/creation/learning)
  /history           Show conversation history
  /clear             Clear current session
  /exit              Exit the program

Examples:
  > What is this video about?
  > Who is mentioned in the first 5 minutes?
  > Find clips suitable for TikTok
        """)

    def change_mode(self, mode_str: str):
        """Change conversation mode"""
        mode_str = mode_str.upper()
        try:
            self.mode = SessionMode[mode_str]
            print(f"Mode changed to: {self.mode.value}")
            self.clear_session()  # Start new session with new mode
        except KeyError:
            print(f"Invalid mode: {mode_str}")
            print("Valid modes: EXPLORATION, CREATION, LEARNING")

    def show_history(self):
        """Show conversation history"""
        if not self.session_id:
            print("No conversation history yet.")
            return

        history = self.interface.get_session_history(self.session_id)
        if not history:
            print("No conversation history yet.")
            return

        print("\nConversation History:")
        for i, msg in enumerate(history, 1):
            role_str = msg.role.capitalize() if hasattr(msg, 'role') else str(msg.get('role', 'Unknown'))
            content = msg.content if hasattr(msg, 'content') else msg.get('content', '')
            print(f"{i}. [{role_str}] {content[:100]}{'...' if len(content) > 100 else ''}")

    def clear_session(self):
        """Clear current session"""
        self.session_id = None
        print("Session cleared. Starting fresh conversation.")

    def format_time(self, start: float, end: float) -> str:
        """Format timestamp"""
        def seconds_to_mmss(seconds):
            mins = int(seconds // 60)
            secs = int(seconds % 60)
            return f"{mins:02d}:{secs:02d}"

        if start == 0 and end == 0:
            return "[Time N/A]"

        return f"{seconds_to_mmss(start)}-{seconds_to_mmss(end)}"

def main():
    """Main entry point"""
    import sys

    if len(sys.argv) > 1:
        data_path = sys.argv[1]
    else:
        data_path = "data/output_pipeline_v3"

    try:
        cli = CLI(data_path)
        cli.run()
    except KeyboardInterrupt:
        print("\n\nGoodbye!")
    except Exception as e:
        print(f"\n[FATAL ERROR] {e}")
        logger.error(f"Fatal error: {e}", exc_info=True)

if __name__ == "__main__":
    main()
```

**ä»£ç é‡**: ~200è¡Œ

---

## äº”ã€å®æ–½è®¡åˆ’

### 5.1 åˆ›å»ºé¡ºåº

1. **ResponseGenerator** (~1å°æ—¶)
   - åˆ›å»ºresponse_generator.py
   - æµ‹è¯•åŸºæœ¬ç”ŸæˆåŠŸèƒ½

2. **ConversationalInterface** (~1å°æ—¶)
   - åˆ›å»ºconversational_interface.py
   - æ›´æ–°__init__.pyå¯¼å‡º
   - æµ‹è¯•ç«¯åˆ°ç«¯æµç¨‹

3. **CLI** (~1å°æ—¶)
   - åˆ›å»ºcli.py
   - æµ‹è¯•äº¤äº’ä½“éªŒ
   - ä¼˜åŒ–è¾“å‡ºæ ¼å¼

### 5.2 æµ‹è¯•ç­–ç•¥

1. **å•å…ƒæµ‹è¯•**: æ¯ä¸ªæ¨¡å—ç‹¬ç«‹æµ‹è¯•
2. **é›†æˆæµ‹è¯•**: å®Œæ•´å¯¹è¯æµç¨‹æµ‹è¯•
3. **äº¤äº’æµ‹è¯•**: CLIå®é™…ä½¿ç”¨ä½“éªŒ

---

## å…­ã€é¢„æœŸæˆæœ

å®Œæˆåå¯å®ç°ï¼š

1. âœ… å®Œæ•´çš„å¯¹è¯ç³»ç»Ÿé—­ç¯
2. âœ… æ”¯æŒ7ç§æŸ¥è¯¢æ„å›¾
3. âœ… å¤šä¼šè¯ç®¡ç†
4. âœ… æ¥æºå¼•ç”¨å’Œæ—¶é—´æˆ³
5. âœ… å‹å¥½çš„CLIäº¤äº’ç•Œé¢

**æ€»ä»£ç é‡**: ~600è¡Œ
**å®Œæˆæ—¶é—´**: 3-4å°æ—¶

---

## ä¸ƒã€ä¸‹ä¸€æ­¥

1. æŒ‰é¡ºåºåˆ›å»º3ä¸ªæ¨¡å—
2. è¿è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•
3. è°ƒä¼˜ä½“éªŒå’Œæ€§èƒ½
4. å‡†å¤‡æ¼”ç¤ºè§†é¢‘


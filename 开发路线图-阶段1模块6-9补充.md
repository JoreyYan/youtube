# é˜¶æ®µ1 æ¨¡å—1.6-1.9 è¯¦ç»†å®ç°

ç»§ç»­ `å¼€å‘è·¯çº¿å›¾-è¯¦ç»†å®æ–½è®¡åˆ’.md` çš„å†…å®¹...

---

## æ¨¡å—1.6-1.9 å®Œæ•´å®ç°

### æ¨¡å—1.6ï¼šåŸå­åŒ–è´¨é‡éªŒè¯å™¨ï¼ˆç»­ï¼‰

#### æµ‹è¯•

```python
# tests/test_validator.py

from parsers import SRTParser, Cleaner
from atomizers import Atomizer, AtomValidator
from utils import load_jsonl, setup_logger
from models import Atom
from config import CLAUDE_API_KEY

logger = setup_logger(__name__)

def test_validator():
    """æµ‹è¯•éªŒè¯å™¨"""
    print("\n" + "="*60)
    print("æµ‹è¯•åŸå­åŒ–è´¨é‡éªŒè¯å™¨")
    print("="*60)

    # åŠ è½½å·²ç”Ÿæˆçš„åŸå­
    try:
        atoms = load_jsonl("data/processed/atoms_10min.jsonl", Atom)
    except FileNotFoundError:
        print("âŒ è¯·å…ˆè¿è¡Œ test_atomizer.py ç”ŸæˆåŸå­æ•°æ®")
        return

    # åŠ è½½åŸå§‹å­—å¹•
    parser = SRTParser()
    utterances = parser.parse("data/raw/test.srt")
    cleaner = Cleaner()
    utterances = cleaner.clean(utterances)
    utterances_10min = [u for u in utterances if u.start_ms < 600000]

    # éªŒè¯
    validator = AtomValidator()
    report = validator.validate(atoms, utterances_10min)

    # æ‰“å°æŠ¥å‘Š
    validator.print_report(report)

    # ä¿å­˜æŠ¥å‘Š
    from utils import save_json
    save_json(report, "data/processed/validation_report.json")
    print("\nâœ“ æŠ¥å‘Šå·²ä¿å­˜åˆ° data/processed/validation_report.json")

    return report

if __name__ == "__main__":
    report = test_validator()
```

#### è¿è¡Œæµ‹è¯•

```bash
python tests/test_validator.py
```

#### éªŒæ”¶æ ‡å‡†

```
âœ… éªŒè¯å™¨èƒ½æ­£å¸¸è¿è¡Œ
âœ… èƒ½æ£€æµ‹å‡ºæ—¶é—´è¦†ç›–ç‡é—®é¢˜
âœ… èƒ½æ£€æµ‹å‡ºæ—¶é—´é—´éš”é—®é¢˜
âœ… èƒ½æ£€æµ‹å‡ºç±»å‹åˆ†å¸ƒå¼‚å¸¸
âœ… ç”Ÿæˆçš„æŠ¥å‘Šæ¸…æ™°å¯è¯»
âœ… è´¨é‡è¯„åˆ†åˆç†
```

**äººå·¥åˆ¤æ–­**:
```
æ ¹æ®éªŒè¯æŠ¥å‘Šå†³å®šï¼š
- è´¨é‡è¯„åˆ† A/B â†’ è¿›å…¥ä¸‹ä¸€æ¨¡å—
- è´¨é‡è¯„åˆ† C â†’ è°ƒæ•´æç¤ºè¯ï¼Œé‡æ–°æµ‹è¯•
- è´¨é‡è¯„åˆ† D â†’ æ£€æŸ¥ä»£ç é€»è¾‘ï¼Œä¿®å¤bug
```

---

### æ¨¡å—1.7ï¼šé›†æˆæµ‹è¯•ï¼ˆ1å°æ—¶ï¼‰

#### ä»»åŠ¡
æµ‹è¯•å®Œæ•´æµç¨‹ï¼šSRTè§£æ â†’ æ¸…æ´— â†’ åŸå­åŒ– â†’ éªŒè¯

#### æ­¥éª¤

**Step 1: åˆ›å»ºé›†æˆæµ‹è¯•è„šæœ¬**

```python
# tests/test_integration.py

"""
é›†æˆæµ‹è¯•ï¼šå®Œæ•´çš„åŸå­åŒ–æµç¨‹

æµç¨‹ï¼š
1. è§£æSRTæ–‡ä»¶
2. æ¸…æ´—å­—å¹•
3. åŸå­åŒ–å¤„ç†
4. è´¨é‡éªŒè¯
5. ä¿å­˜ç»“æœ
"""

from parsers import SRTParser, Cleaner
from atomizers import Atomizer, AtomValidator
from utils import save_jsonl, save_json, setup_logger
from config import CLAUDE_API_KEY
import time

logger = setup_logger(__name__)

def run_integration_test(
    srt_file: str,
    output_prefix: str,
    time_limit_ms: int = 600000,  # é»˜è®¤10åˆ†é’Ÿ
    batch_size: int = 50
):
    """
    è¿è¡Œå®Œæ•´çš„é›†æˆæµ‹è¯•

    Args:
        srt_file: SRTæ–‡ä»¶è·¯å¾„
        output_prefix: è¾“å‡ºæ–‡ä»¶å‰ç¼€
        time_limit_ms: å¤„ç†æ—¶é•¿é™åˆ¶ï¼ˆæ¯«ç§’ï¼‰
        batch_size: æ‰¹å¤„ç†å¤§å°
    """
    print("\n" + "="*60)
    print("é›†æˆæµ‹è¯• - å®Œæ•´åŸå­åŒ–æµç¨‹")
    print("="*60)

    start_time = time.time()

    # ========== Step 1: è§£æSRT ==========
    print("\n[1/5] è§£æSRTæ–‡ä»¶...")
    parser = SRTParser()
    utterances = parser.parse(srt_file)
    print(f"  âœ“ è§£æå®Œæˆï¼š{len(utterances)}æ¡å­—å¹•")

    # ========== Step 2: æ¸…æ´— ==========
    print("\n[2/5] æ¸…æ´—å­—å¹•...")
    cleaner = Cleaner()
    utterances_clean = cleaner.clean(utterances)
    print(f"  âœ“ æ¸…æ´—å®Œæˆï¼š{len(utterances_clean)}æ¡ï¼ˆç§»é™¤{cleaner.removed_count}æ¡ï¼‰")

    # æˆªå–æŒ‡å®šæ—¶é•¿
    utterances_limited = [u for u in utterances_clean if u.start_ms < time_limit_ms]
    print(f"  âœ“ æˆªå–å‰{time_limit_ms/60000:.1f}åˆ†é’Ÿï¼š{len(utterances_limited)}æ¡")

    # ========== Step 3: åŸå­åŒ– ==========
    print("\n[3/5] åŸå­åŒ–å¤„ç†...")
    atomizer = Atomizer(CLAUDE_API_KEY, batch_size=batch_size)
    atoms = atomizer.atomize(utterances_limited)
    print(f"  âœ“ åŸå­åŒ–å®Œæˆï¼š{len(atoms)}ä¸ªåŸå­")

    # APIç»Ÿè®¡
    stats = atomizer.client.get_stats()
    print(f"  APIè°ƒç”¨: {stats['total_calls']}æ¬¡")
    print(f"  é¢„ä¼°æˆæœ¬: {stats['estimated_cost']}")

    # ========== Step 4: è´¨é‡éªŒè¯ ==========
    print("\n[4/5] è´¨é‡éªŒè¯...")
    validator = AtomValidator()
    report = validator.validate(atoms, utterances_limited)
    validator.print_report(report)

    # ========== Step 5: ä¿å­˜ç»“æœ ==========
    print("\n[5/5] ä¿å­˜ç»“æœ...")

    atoms_file = f"data/processed/{output_prefix}_atoms.jsonl"
    report_file = f"data/processed/{output_prefix}_report.json"
    stats_file = f"data/processed/{output_prefix}_stats.json"

    save_jsonl(atoms, atoms_file)
    save_json(report, report_file)
    save_json(stats, stats_file)

    print(f"  âœ“ åŸå­æ•°æ®: {atoms_file}")
    print(f"  âœ“ éªŒè¯æŠ¥å‘Š: {report_file}")
    print(f"  âœ“ APIç»Ÿè®¡: {stats_file}")

    # ========== æ€»ç»“ ==========
    elapsed_time = time.time() - start_time
    print("\n" + "="*60)
    print("é›†æˆæµ‹è¯•å®Œæˆ")
    print("="*60)
    print(f"æ€»è€—æ—¶: {elapsed_time:.1f}ç§’")
    print(f"è´¨é‡è¯„åˆ†: {report['quality_score']}")
    print(f"é¢„ä¼°æˆæœ¬: {stats['estimated_cost']}")

    # å†³ç­–å»ºè®®
    if report['quality_score'] in ['ä¼˜ç§€ (A)', 'è‰¯å¥½ (B)']:
        print("\nâœ… è´¨é‡è¾¾æ ‡ï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µï¼")
    elif report['quality_score'] == 'åˆæ ¼ (C)':
        print("\nâš ï¸  è´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®ä¼˜åŒ–æç¤ºè¯åé‡è¯•")
    else:
        print("\nâŒ è´¨é‡ä¸åˆæ ¼ï¼Œå¿…é¡»ä¿®å¤é—®é¢˜åé‡è¯•")

    return atoms, report, stats

if __name__ == "__main__":
    import sys

    if not CLAUDE_API_KEY:
        print("âŒ æœªé…ç½®CLAUDE_API_KEY")
        sys.exit(1)

    # è¿è¡Œé›†æˆæµ‹è¯•ï¼ˆå‰10åˆ†é’Ÿï¼‰
    atoms, report, stats = run_integration_test(
        srt_file="data/raw/test.srt",
        output_prefix="test_10min",
        time_limit_ms=600000,  # 10åˆ†é’Ÿ
        batch_size=50
    )
```

#### è¿è¡Œæµ‹è¯•

```bash
python tests/test_integration.py
```

#### é¢„æœŸè¾“å‡º

```
============================================================
é›†æˆæµ‹è¯• - å®Œæ•´åŸå­åŒ–æµç¨‹
============================================================

[1/5] è§£æSRTæ–‡ä»¶...
  âœ“ è§£æå®Œæˆï¼š3580æ¡å­—å¹•

[2/5] æ¸…æ´—å­—å¹•...
  âœ“ æ¸…æ´—å®Œæˆï¼š3200æ¡ï¼ˆç§»é™¤380æ¡ï¼‰
  âœ“ æˆªå–å‰10.0åˆ†é’Ÿï¼š1850æ¡

[3/5] åŸå­åŒ–å¤„ç†...
å¤„ç†æ‰¹æ¬¡ 1/37...
  âœ“ ç”Ÿæˆ12ä¸ªåŸå­
...
  âœ“ åŸå­åŒ–å®Œæˆï¼š145ä¸ªåŸå­
  APIè°ƒç”¨: 37æ¬¡
  é¢„ä¼°æˆæœ¬: $4.20

[4/5] è´¨é‡éªŒè¯...
============================================================
åŸå­åŒ–è´¨é‡éªŒè¯æŠ¥å‘Š
============================================================
æ€»åŸå­æ•°: 145
æ—¶é—´è¦†ç›–ç‡: 94.2%
è´¨é‡è¯„åˆ†: è‰¯å¥½ (B)
...

[5/5] ä¿å­˜ç»“æœ...
  âœ“ åŸå­æ•°æ®: data/processed/test_10min_atoms.jsonl
  âœ“ éªŒè¯æŠ¥å‘Š: data/processed/test_10min_report.json
  âœ“ APIç»Ÿè®¡: data/processed/test_10min_stats.json

============================================================
é›†æˆæµ‹è¯•å®Œæˆ
============================================================
æ€»è€—æ—¶: 180.5ç§’
è´¨é‡è¯„åˆ†: è‰¯å¥½ (B)
é¢„ä¼°æˆæœ¬: $4.20

âœ… è´¨é‡è¾¾æ ‡ï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µï¼
```

#### éªŒæ”¶æ ‡å‡†

```
âœ… å®Œæ•´æµç¨‹èƒ½è·‘é€š
âœ… æ‰€æœ‰æ­¥éª¤æ­£å¸¸æ‰§è¡Œ
âœ… è´¨é‡è¯„åˆ†è¾¾åˆ°Bæˆ–ä»¥ä¸Š
âœ… APIæˆæœ¬åœ¨å¯æ¥å—èŒƒå›´å†…ï¼ˆ<$5/10åˆ†é’Ÿï¼‰
âœ… è¾“å‡ºæ–‡ä»¶éƒ½æ­£ç¡®ç”Ÿæˆ
âœ… å¤„ç†æ—¶é—´åˆç†ï¼ˆ<5åˆ†é’Ÿå®é™…å¤„ç†æ—¶é—´ï¼‰
```

---

### æ¨¡å—1.8ï¼šæç¤ºè¯ä¼˜åŒ–ï¼ˆ1-2å°æ—¶ï¼‰

#### ä»»åŠ¡
æ ¹æ®éªŒè¯ç»“æœï¼Œè¿­ä»£ä¼˜åŒ–åŸå­åŒ–æç¤ºè¯

#### æ­¥éª¤

**Step 1: åˆ†æé—®é¢˜**

```python
# scripts/analyze_atoms.py

"""
åˆ†æåŸå­åŒ–ç»“æœï¼Œæ‰¾å‡ºå¸¸è§é—®é¢˜
"""

from utils import load_jsonl
from models import Atom
from collections import Counter

def analyze_atoms(atoms_file: str):
    """åˆ†æåŸå­åŒ–ç»“æœ"""
    atoms = load_jsonl(atoms_file, Atom)

    print("\n" + "="*60)
    print("åŸå­åŒ–ç»“æœåˆ†æ")
    print("="*60)

    # ç»Ÿè®¡1: åŸå­é•¿åº¦åˆ†å¸ƒ
    lengths = [a.duration_seconds for a in atoms]
    print(f"\né•¿åº¦ç»Ÿè®¡:")
    print(f"  å¹³å‡: {sum(lengths)/len(lengths):.1f}ç§’")
    print(f"  æœ€çŸ­: {min(lengths):.1f}ç§’")
    print(f"  æœ€é•¿: {max(lengths):.1f}ç§’")
    print(f"  ä¸­ä½æ•°: {sorted(lengths)[len(lengths)//2]:.1f}ç§’")

    # æ‰¾å‡ºå¼‚å¸¸çŸ­çš„åŸå­
    very_short = [a for a in atoms if a.duration_seconds < 5]
    if very_short:
        print(f"\nâš ï¸  è¿‡çŸ­åŸå­ (<5ç§’): {len(very_short)}ä¸ª")
        for a in very_short[:3]:
            print(f"  {a.atom_id}: {a.merged_text[:50]}")

    # æ‰¾å‡ºå¼‚å¸¸é•¿çš„åŸå­
    very_long = [a for a in atoms if a.duration_seconds > 600]
    if very_long:
        print(f"\nâš ï¸  è¿‡é•¿åŸå­ (>10åˆ†é’Ÿ): {len(very_long)}ä¸ª")
        for a in very_long[:3]:
            print(f"  {a.atom_id}: {a.merged_text[:50]}")

    # ç»Ÿè®¡2: ç±»å‹åˆ†å¸ƒ
    type_counter = Counter(a.type for a in atoms)
    print(f"\nç±»å‹åˆ†å¸ƒ:")
    for t, count in type_counter.most_common():
        print(f"  {t}: {count}ä¸ª ({count/len(atoms)*100:.1f}%)")

    # æ£€æŸ¥ç±»å‹å¤šæ ·æ€§
    if len(type_counter) < 3:
        print(f"\nâš ï¸  ç±»å‹å¤šæ ·æ€§ä¸è¶³ï¼ˆåªæœ‰{len(type_counter)}ç§ç±»å‹ï¼‰")

    # ç»Ÿè®¡3: å®Œæ•´æ€§åˆ†å¸ƒ
    completeness_counter = Counter(a.completeness for a in atoms)
    print(f"\nå®Œæ•´æ€§åˆ†å¸ƒ:")
    for c, count in completeness_counter.most_common():
        print(f"  {c}: {count}ä¸ª ({count/len(atoms)*100:.1f}%)")

    # ç»Ÿè®¡4: å®Œæ•´ç‰‡æ®µ
    complete_segments = [a for a in atoms if a.type == "complete_segment"]
    print(f"\nå®Œæ•´ç‰‡æ®µ: {len(complete_segments)}ä¸ª")
    if complete_segments:
        print("ç¤ºä¾‹:")
        for a in complete_segments[:2]:
            print(f"  {a.atom_id} ({a.duration_seconds/60:.1f}åˆ†é’Ÿ): {a.merged_text[:60]}...")

    # ç»Ÿè®¡5: è¾¹ç•Œæ£€æŸ¥ï¼ˆç›¸é‚»åŸå­çš„ä¸»é¢˜å˜åŒ–ï¼‰
    print(f"\nè¾¹ç•Œåˆç†æ€§æ£€æŸ¥ï¼ˆéšæœºæŠ½æ ·ï¼‰:")
    import random
    samples = random.sample(range(1, len(atoms)-1), min(5, len(atoms)-2))
    for i in samples:
        prev_atom = atoms[i-1]
        curr_atom = atoms[i]
        print(f"\n  è¾¹ç•Œ {i}:")
        print(f"    å‰: [{prev_atom.type}] {prev_atom.merged_text[-40:]}")
        print(f"    å: [{curr_atom.type}] {curr_atom.merged_text[:40]}")

if __name__ == "__main__":
    analyze_atoms("data/processed/test_10min_atoms.jsonl")
```

**Step 2: æ ¹æ®åˆ†æç»“æœè°ƒæ•´æç¤ºè¯**

æ ¹æ®å¸¸è§é—®é¢˜ï¼Œåˆ›å»ºä¼˜åŒ–ç‰ˆæœ¬ï¼š

```
# prompts/atomize_v2.txt

ï¼ˆæ ¹æ®å®é™…é—®é¢˜ä¿®æ”¹ï¼‰

ä¾‹å¦‚ï¼Œå¦‚æœå‘ç°ï¼š
- é—®é¢˜1: è¾¹ç•Œåˆ‡åˆ†è¿‡ç»† â†’ å¼ºè°ƒ"è¯­ä¹‰å®Œæ•´"
- é—®é¢˜2: ç±»å‹åˆ¤æ–­ä¸å‡† â†’ å¢åŠ ç±»å‹å®šä¹‰å’Œç¤ºä¾‹
- é—®é¢˜3: å®Œæ•´ç‰‡æ®µè¯†åˆ«ä¸è¶³ â†’ å¼ºåŒ–complete_segmentçš„åˆ¤æ–­æ ‡å‡†

ç¤ºä¾‹ä¼˜åŒ–ç‰ˆæœ¬ï¼š

ä½ æ˜¯ä¸€ä¸ªè§†é¢‘å†…å®¹åˆ†æä¸“å®¶ã€‚æˆ‘ä¼šç»™ä½ ä¸€æ®µç›´æ’­çš„å­—å¹•ç‰‡æ®µï¼Œä½ çš„ä»»åŠ¡æ˜¯æŠŠå®ƒä»¬åˆå¹¶æˆ"è¯­ä¹‰å®Œæ•´çš„ä¿¡æ¯å•å…ƒ"ã€‚

ã€æ ¸å¿ƒè§„åˆ™ - åŠ å¼ºç‰ˆã€‘

1. åŸå­é•¿åº¦çµæ´»ï¼š
   - çŸ­ï¼š10-30ç§’ï¼ˆå•æ¬¡äº’åŠ¨ã€ç®€çŸ­è¯„è®ºï¼‰
   - ä¸­ï¼š1-5åˆ†é’Ÿï¼ˆå®Œæ•´è§‚ç‚¹ã€å°æ•…äº‹ã€å®Œæ•´å›åº”ï¼‰
   - é•¿ï¼š5-15åˆ†é’Ÿï¼ˆå®Œæ•´å†å²å™è¿°ã€æ·±åº¦è®ºè¿°ï¼‰

   âš ï¸ é‡è¦ï¼šä¸è¦ä¸ºäº†ç»Ÿä¸€é•¿åº¦è€Œå¼ºè¡Œåˆ‡åˆ†ï¼è¯­ä¹‰å®Œæ•´æ€§ä¼˜å…ˆï¼

2. è¾¹ç•Œåˆ¤æ–­æ ‡å‡†ï¼ˆæ›´ä¸¥æ ¼ï¼‰ï¼š
   - ä¸»é¢˜æ˜ç¡®è½¬æ¢ï¼ˆä¸æ˜¯ç»†å¾®å˜åŒ–ï¼‰â†’ æ–°åŸå­
   - é•¿æ—¶é—´åœé¡¿ï¼ˆ>8ç§’ï¼‰â†’ æ–°åŸå­
   - æ˜ç¡®çš„è¯é¢˜è½¬æ¢è¯ï¼ˆ"é‚£æˆ‘ä»¬è¯´ç‚¹åˆ«çš„"ã€"å¥½ï¼Œä¸‹ä¸€ä¸ªé—®é¢˜"ï¼‰â†’ æ–°åŸå­
   - ä»å™äº‹è½¬åˆ°äº’åŠ¨ï¼ˆæˆ–åå‘ï¼‰â†’ æ–°åŸå­

   âš ï¸ ä¸è¦å› ä¸ºå°çš„åœé¡¿å°±åˆ‡åˆ†ï¼ä¿æŒè¯­ä¹‰è¿è´¯æ€§ï¼

3. å®Œæ•´ç‰‡æ®µè¯†åˆ«ï¼ˆcomplete_segmentï¼‰- åŠ å¼ºæ ‡å‡†ï¼š
   å¿…é¡»åŒæ—¶æ»¡è¶³ï¼š
   âœ… æ—¶é•¿ â‰¥ 5åˆ†é’Ÿ
   âœ… ä¸»é¢˜é«˜åº¦ç»Ÿä¸€ï¼ˆå›´ç»•ä¸€ä¸ªæ ¸å¿ƒè¯é¢˜ï¼‰
   âœ… æœ‰æ¸…æ™°çš„å¼€å§‹å’Œç»“æŸ
   âœ… é€»è¾‘å®Œæ•´ï¼ˆèƒŒæ™¯-å‘å±•-ç»“è®º æˆ– è§‚ç‚¹-è®ºæ®-æ€»ç»“ï¼‰
   âœ… å¯ä»¥ç‹¬ç«‹ä½œä¸ºä¸€ä¸ªè§†é¢‘ç‰‡æ®µä½¿ç”¨

   å¦‚æœåªæ»¡è¶³éƒ¨åˆ†æ¡ä»¶ â†’ æ ‡è®°ä¸º type: "fragment"

4. ç±»å‹åˆ†ç±»ï¼ˆæ›´ç»†è‡´ï¼‰ï¼š
   - å™è¿°å†å²ï¼šè®²è¿°å…·ä½“å†å²äº‹ä»¶ï¼Œæœ‰æ—¶é—´ã€äººç‰©ã€äº‹ä»¶
   - åˆ†æè§‚ç‚¹ï¼šè¡¨è¾¾çœ‹æ³•ã€åˆ†æåŸå› ã€è¯„ä»·äº‹ä»¶
   - å›åº”å¼¹å¹•ï¼šç›´æ¥å›åº”è§‚ä¼—æé—®æˆ–è¯„è®º
   - è¯»è§‚ä¼—æ¥ä¿¡ï¼šæœ—è¯»å¹¶å›åº”è§‚ä¼—ä¿¡ä»¶
   - é—²èŠäº’åŠ¨ï¼šè½»æ¾èŠå¤©ã€æ— å…³ä¸»é¢˜çš„äº’åŠ¨
   - å¼•å…¥è¯é¢˜ï¼šå¼€åœºç™½ã€è¿‡æ¸¡è¯­ã€è¯é¢˜å¼•å…¥

   âš ï¸ æ³¨æ„åŒºåˆ†"å™è¿°äº‹å®"å’Œ"å‘è¡¨è§‚ç‚¹"ï¼

ã€è¾“å‡ºæ ¼å¼ã€‘
JSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
{
  "atom_id": "A001",
  "start_ms": 500000,
  "end_ms": 510000,
  "duration_ms": 10000,
  "merged_text": "å®Œæ•´çš„åˆå¹¶æ–‡æœ¬",
  "type": "å™è¿°å†å²",  // ä½¿ç”¨ä¸Šè¿°6ç§ç±»å‹ä¹‹ä¸€
  "completeness": "å®Œæ•´",  // æˆ–"éœ€è¦ä¸Šä¸‹æ–‡"
  "source_utterance_ids": [1,2,3]
}

ã€è´¨é‡è‡ªæ£€ã€‘
åœ¨è¾“å‡ºä¹‹å‰ï¼Œè¯·ç¡®è®¤ï¼š
âœ… æ²¡æœ‰æŠŠä¸€å¥å®Œæ•´çš„è¯åˆ‡æˆä¸¤ä¸ªåŸå­
âœ… ç±»å‹åˆ¤æ–­åŸºäºå†…å®¹ï¼Œä¸æ˜¯åŸºäºé•¿åº¦
âœ… å®Œæ•´ç‰‡æ®µçœŸçš„å¯ä»¥ç‹¬ç«‹ç†è§£
âœ… æ—¶é—´è¿ç»­ï¼Œæ²¡æœ‰é—æ¼
âœ… atom_id è¿ç»­ç¼–å·
```

**Step 3: A/Bæµ‹è¯•**

```python
# scripts/compare_prompts.py

"""
å¯¹æ¯”ä¸åŒæç¤ºè¯ç‰ˆæœ¬çš„æ•ˆæœ
"""

from atomizers import Atomizer
from parsers import SRTParser, Cleaner
from utils import save_jsonl
from config import CLAUDE_API_KEY

def test_prompt_version(prompt_file: str, output_file: str):
    """æµ‹è¯•æŒ‡å®šæç¤ºè¯ç‰ˆæœ¬"""
    # è§£æå­—å¹•
    parser = SRTParser()
    utterances = parser.parse("data/raw/test.srt")

    cleaner = Cleaner()
    utterances = cleaner.clean(utterances)
    utterances = [u for u in utterances if u.start_ms < 600000]  # å‰10åˆ†é’Ÿ

    # åŸå­åŒ–ï¼ˆä½¿ç”¨æŒ‡å®šæç¤ºè¯ï¼‰
    atomizer = Atomizer(CLAUDE_API_KEY, batch_size=50)

    # æ›¿æ¢æç¤ºè¯
    with open(prompt_file, 'r', encoding='utf-8') as f:
        atomizer.prompt_template = f.read()

    atoms = atomizer.atomize(utterances)

    # ä¿å­˜
    save_jsonl(atoms, output_file)

    # è¿”å›ç»Ÿè®¡
    stats = atomizer.client.get_stats()
    return atoms, stats

if __name__ == "__main__":
    print("æµ‹è¯• v1 æç¤ºè¯...")
    atoms_v1, stats_v1 = test_prompt_version(
        "prompts/atomize_v1.txt",
        "data/processed/atoms_v1.jsonl"
    )

    print("\næµ‹è¯• v2 æç¤ºè¯...")
    atoms_v2, stats_v2 = test_prompt_version(
        "prompts/atomize_v2.txt",
        "data/processed/atoms_v2.jsonl"
    )

    print("\nå¯¹æ¯”ç»“æœ:")
    print(f"v1: {len(atoms_v1)}ä¸ªåŸå­, {stats_v1['estimated_cost']}")
    print(f"v2: {len(atoms_v2)}ä¸ªåŸå­, {stats_v2['estimated_cost']}")

    # è¿è¡Œåˆ†æå¯¹æ¯”
    print("\n" + "="*60)
    print("v1 åˆ†æ:")
    from scripts.analyze_atoms import analyze_atoms
    analyze_atoms("data/processed/atoms_v1.jsonl")

    print("\n" + "="*60)
    print("v2 åˆ†æ:")
    analyze_atoms("data/processed/atoms_v2.jsonl")
```

#### éªŒæ”¶æ ‡å‡†

```
âœ… èƒ½è¯†åˆ«å‡ºè´¨é‡é—®é¢˜
âœ… é’ˆå¯¹æ€§åœ°è°ƒæ•´æç¤ºè¯
âœ… æ–°ç‰ˆæœ¬è´¨é‡æœ‰æå‡
âœ… è¿­ä»£2-3æ¬¡åè¾¾åˆ°Aæˆ–Bè¯„åˆ†
```

---

### æ¨¡å—1.9ï¼šå…¨è§†é¢‘æµ‹è¯•ï¼ˆ2-3å°æ—¶ï¼‰

#### ä»»åŠ¡
åœ¨å®Œæ•´2å°æ—¶è§†é¢‘ä¸Šæµ‹è¯•ï¼ŒéªŒè¯å¯æ‰©å±•æ€§

#### æ­¥éª¤

**Step 1: åˆ›å»ºå…¨è§†é¢‘æµ‹è¯•è„šæœ¬**

```python
# scripts/process_full_video.py

"""
å¤„ç†å®Œæ•´è§†é¢‘ï¼ˆ2å°æ—¶ï¼‰
"""

from tests.test_integration import run_integration_test
from config import CLAUDE_API_KEY
import sys

def process_full_video():
    """å¤„ç†å®Œæ•´è§†é¢‘"""
    if not CLAUDE_API_KEY:
        print("âŒ æœªé…ç½®CLAUDE_API_KEY")
        sys.exit(1)

    # è¯¢é—®ç”¨æˆ·ç¡®è®¤
    print("\nâš ï¸  è­¦å‘Šï¼šå¤„ç†2å°æ—¶è§†é¢‘å¯èƒ½éœ€è¦ï¼š")
    print("   - æ—¶é—´: 20-40åˆ†é’Ÿ")
    print("   - æˆæœ¬: $40-60")
    print("   - APIè°ƒç”¨: 400-500æ¬¡")

    confirm = input("\nç¡®è®¤ç»§ç»­ï¼Ÿ(yes/no): ")
    if confirm.lower() != 'yes':
        print("å·²å–æ¶ˆ")
        return

    # è¿è¡Œå®Œæ•´å¤„ç†
    atoms, report, stats = run_integration_test(
        srt_file="data/raw/test.srt",
        output_prefix="full_video",
        time_limit_ms=7200000,  # 2å°æ—¶
        batch_size=50
    )

    # é¢å¤–åˆ†æ
    print("\n" + "="*60)
    print("å®Œæ•´è§†é¢‘å¤„ç†ç»“æœåˆ†æ")
    print("="*60)

    # å®Œæ•´ç‰‡æ®µç»Ÿè®¡
    complete_segments = [a for a in atoms if a.type == "complete_segment"]
    print(f"\nå®Œæ•´ç‰‡æ®µ: {len(complete_segments)}ä¸ª")
    if complete_segments:
        total_complete_duration = sum(a.duration_ms for a in complete_segments) / 1000
        print(f"å®Œæ•´ç‰‡æ®µæ€»æ—¶é•¿: {total_complete_duration/60:.1f}åˆ†é’Ÿ")
        print(f"å æ¯”: {total_complete_duration/7200*100:.1f}%")

    # ç±»å‹æ—¶é•¿åˆ†å¸ƒ
    type_durations = {}
    for atom in atoms:
        if atom.type not in type_durations:
            type_durations[atom.type] = 0
        type_durations[atom.type] += atom.duration_ms / 1000

    print(f"\nå„ç±»å‹æ—¶é•¿å æ¯”:")
    for t, duration in sorted(type_durations.items(), key=lambda x: -x[1]):
        print(f"  {t}: {duration/60:.1f}åˆ†é’Ÿ ({duration/7200*100:.1f}%)")

    return atoms, report, stats

if __name__ == "__main__":
    process_full_video()
```

**Step 2: æ€§èƒ½ç›‘æ§**

```python
# utils/progress.py

"""
è¿›åº¦ç›‘æ§å·¥å…·
"""

from rich.progress import Progress, SpinnerColumn, TimeElapsedColumn, BarColumn, TextColumn

class ProgressMonitor:
    """å¤„ç†è¿›åº¦ç›‘æ§å™¨"""

    def __init__(self):
        self.progress = None
        self.task = None

    def __enter__(self):
        self.progress = Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeElapsedColumn(),
        )
        self.progress.start()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.progress:
            self.progress.stop()

    def add_task(self, description: str, total: int):
        """æ·»åŠ ä»»åŠ¡"""
        self.task = self.progress.add_task(description, total=total)
        return self.task

    def update(self, advance: int = 1):
        """æ›´æ–°è¿›åº¦"""
        if self.progress and self.task is not None:
            self.progress.update(self.task, advance=advance)
```

ä¿®æ”¹ Atomizer ç±»ä»¥æ”¯æŒè¿›åº¦ç›‘æ§ï¼š

```python
# atomizers/atomizer.py (æ›´æ–°)

# åœ¨ atomize æ–¹æ³•ä¸­æ·»åŠ è¿›åº¦æ”¯æŒ
def atomize(
    self,
    utterances: List[Utterance],
    start_atom_id: int = 1,
    show_progress: bool = True
) -> List[Atom]:
    """åŸå­åŒ–å¤„ç†ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰"""
    atoms = []
    total_batches = (len(utterances) + self.batch_size - 1) // self.batch_size
    atom_counter = start_atom_id

    logger.info(f"å¼€å§‹åŸå­åŒ–ï¼Œå…±{len(utterances)}æ¡å­—å¹•ï¼Œåˆ†{total_batches}æ‰¹å¤„ç†")

    if show_progress:
        from utils.progress import ProgressMonitor
        with ProgressMonitor() as monitor:
            monitor.add_task("åŸå­åŒ–å¤„ç†ä¸­...", total=total_batches)

            for i in range(0, len(utterances), self.batch_size):
                batch = utterances[i:i + self.batch_size]
                try:
                    batch_atoms = self._process_batch(batch, atom_counter)
                    atoms.extend(batch_atoms)
                    atom_counter += len(batch_atoms)
                    monitor.update(1)
                except Exception as e:
                    logger.error(f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
                    monitor.update(1)
                    continue
    else:
        # åŸæœ‰é€»è¾‘
        for i in range(0, len(utterances), self.batch_size):
            batch = utterances[i:i + self.batch_size]
            batch_num = i // self.batch_size + 1
            logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches}...")
            try:
                batch_atoms = self._process_batch(batch, atom_counter)
                atoms.extend(batch_atoms)
                atom_counter += len(batch_atoms)
                logger.info(f"  âœ“ ç”Ÿæˆ{len(batch_atoms)}ä¸ªåŸå­")
            except Exception as e:
                logger.error(f"  âœ— æ‰¹æ¬¡{batch_num}å¤„ç†å¤±è´¥: {e}")
                continue

    self.total_atoms = len(atoms)
    logger.info(f"åŸå­åŒ–å®Œæˆï¼Œå…±ç”Ÿæˆ{self.total_atoms}ä¸ªåŸå­")

    return atoms
```

#### è¿è¡Œæµ‹è¯•

```bash
python scripts/process_full_video.py
```

#### é¢„æœŸè¾“å‡º

```
âš ï¸  è­¦å‘Šï¼šå¤„ç†2å°æ—¶è§†é¢‘å¯èƒ½éœ€è¦ï¼š
   - æ—¶é—´: 20-40åˆ†é’Ÿ
   - æˆæœ¬: $40-60
   - APIè°ƒç”¨: 400-500æ¬¡

ç¡®è®¤ç»§ç»­ï¼Ÿ(yes/no): yes

============================================================
é›†æˆæµ‹è¯• - å®Œæ•´åŸå­åŒ–æµç¨‹
============================================================

[1/5] è§£æSRTæ–‡ä»¶...
  âœ“ è§£æå®Œæˆï¼š14320æ¡å­—å¹•

[2/5] æ¸…æ´—å­—å¹•...
  âœ“ æ¸…æ´—å®Œæˆï¼š12800æ¡ï¼ˆç§»é™¤1520æ¡ï¼‰
  âœ“ æˆªå–å‰120.0åˆ†é’Ÿï¼š12800æ¡

[3/5] åŸå­åŒ–å¤„ç†...
åŸå­åŒ–å¤„ç†ä¸­... â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% 00:25:30
  âœ“ åŸå­åŒ–å®Œæˆï¼š580ä¸ªåŸå­
  APIè°ƒç”¨: 256æ¬¡
  é¢„ä¼°æˆæœ¬: $48.50

[4/5] è´¨é‡éªŒè¯...
============================================================
åŸå­åŒ–è´¨é‡éªŒè¯æŠ¥å‘Š
============================================================
æ€»åŸå­æ•°: 580
æ—¶é—´è¦†ç›–ç‡: 92.8%
è´¨é‡è¯„åˆ†: è‰¯å¥½ (B)

é•¿åº¦åˆ†å¸ƒ:
  short_(<30s): 120
  medium_(30s-5min): 425
  long_(>5min): 35
  avg_seconds: 124.8
  max_seconds: 890.0
  min_seconds: 8.5

ç±»å‹åˆ†å¸ƒ:
  å™è¿°å†å²: 285
  å›åº”å¼¹å¹•: 178
  åˆ†æè§‚ç‚¹: 82
  é—²èŠäº’åŠ¨: 25
  è¯»è§‚ä¼—æ¥ä¿¡: 8
  å¼•å…¥è¯é¢˜: 2

æ—¶é—´é—´éš” (>30ç§’): 15ä¸ª
  ...

âš ï¸  è­¦å‘Š (2ä¸ª):
  - æ—¶é—´è¦†ç›–ç‡åä½: 92.8% (å»ºè®®>95%)
  - æ—¶é—´é—´éš”è¿‡å¤š: 15ä¸ªå¤§é—´éš” (>10%)

============================================================

[5/5] ä¿å­˜ç»“æœ...
  âœ“ åŸå­æ•°æ®: data/processed/full_video_atoms.jsonl
  âœ“ éªŒè¯æŠ¥å‘Š: data/processed/full_video_report.json
  âœ“ APIç»Ÿè®¡: data/processed/full_video_stats.json

============================================================
é›†æˆæµ‹è¯•å®Œæˆ
============================================================
æ€»è€—æ—¶: 1850.5ç§’
è´¨é‡è¯„åˆ†: è‰¯å¥½ (B)
é¢„ä¼°æˆæœ¬: $48.50

âœ… è´¨é‡è¾¾æ ‡ï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µï¼

============================================================
å®Œæ•´è§†é¢‘å¤„ç†ç»“æœåˆ†æ
============================================================

å®Œæ•´ç‰‡æ®µ: 12ä¸ª
å®Œæ•´ç‰‡æ®µæ€»æ—¶é•¿: 85.5åˆ†é’Ÿ
å æ¯”: 71.2%

å„ç±»å‹æ—¶é•¿å æ¯”:
  å™è¿°å†å²: 68.5åˆ†é’Ÿ (57.1%)
  å›åº”å¼¹å¹•: 28.2åˆ†é’Ÿ (23.5%)
  åˆ†æè§‚ç‚¹: 15.8åˆ†é’Ÿ (13.2%)
  é—²èŠäº’åŠ¨: 5.2åˆ†é’Ÿ (4.3%)
  è¯»è§‚ä¼—æ¥ä¿¡: 1.8åˆ†é’Ÿ (1.5%)
  å¼•å…¥è¯é¢˜: 0.5åˆ†é’Ÿ (0.4%)
```

#### éªŒæ”¶æ ‡å‡†

```
âœ… èƒ½æˆåŠŸå¤„ç†å®Œæ•´2å°æ—¶è§†é¢‘
âœ… å¤„ç†æ—¶é—´<40åˆ†é’Ÿ
âœ… APIæˆæœ¬<$60
âœ… è´¨é‡è¯„åˆ†è¾¾åˆ°Bæˆ–ä»¥ä¸Š
âœ… æ²¡æœ‰å†…å­˜æº¢å‡ºæˆ–å´©æºƒ
âœ… å®Œæ•´ç‰‡æ®µè¯†åˆ«ç‡åˆç†ï¼ˆè‡³å°‘è¯†åˆ«å‡º5-10ä¸ªï¼‰
âœ… å®Œæ•´ç‰‡æ®µå æ¯”åˆç†ï¼ˆ50-80%ï¼‰
```

**äººå·¥éªŒæ”¶**:
```
éšæœºæŠ½æ ·20ä¸ªåŸå­è¿›è¡Œäººå·¥æ£€æŸ¥ï¼š
âœ… è¾¹ç•Œåˆç†ï¼ˆ90%+ï¼‰
âœ… ç±»å‹å‡†ç¡®ï¼ˆ85%+ï¼‰
âœ… æ–‡æœ¬å®Œæ•´ï¼ˆ95%+ï¼‰
âœ… å®Œæ•´ç‰‡æ®µåˆ¤æ–­åˆç†ï¼ˆ80%+ï¼‰
```

**æŠ½æ ·æ£€æŸ¥è„šæœ¬**:

```python
# scripts/manual_review.py

"""
äººå·¥å®¡æ ¸è¾…åŠ©å·¥å…·
"""

from utils import load_jsonl
from models import Atom
import random

def random_sample_review(atoms_file: str, sample_size: int = 20):
    """éšæœºæŠ½æ ·åŸå­è¿›è¡Œäººå·¥å®¡æ ¸"""
    atoms = load_jsonl(atoms_file, Atom)

    # éšæœºæŠ½æ ·
    samples = random.sample(atoms, min(sample_size, len(atoms)))

    print("\n" + "="*60)
    print(f"äººå·¥å®¡æ ¸ - éšæœºæŠ½æ ·{len(samples)}ä¸ªåŸå­")
    print("="*60)

    for i, atom in enumerate(samples, 1):
        print(f"\nã€åŸå­ {i}/{len(samples)}ã€‘")
        print(f"ID: {atom.atom_id}")
        print(f"æ—¶é—´: {atom.start_time} - {atom.end_time} ({atom.duration_seconds:.1f}ç§’)")
        print(f"ç±»å‹: {atom.type}")
        print(f"å®Œæ•´æ€§: {atom.completeness}")
        print(f"æ–‡æœ¬: {atom.merged_text}")
        print("\n" + "-"*60)

        # ç­‰å¾…äººå·¥è¯„åˆ†
        print("è¯·è¯„ä»·ï¼š")
        print("1 - è¾¹ç•Œåˆç†ï¼Ÿ(y/n)")
        print("2 - ç±»å‹å‡†ç¡®ï¼Ÿ(y/n)")
        print("3 - æ–‡æœ¬å®Œæ•´ï¼Ÿ(y/n)")
        print("4 - å®Œæ•´æ€§åˆ¤æ–­åˆç†ï¼Ÿ(y/n)")
        print("è¾“å…¥è¯„åˆ†ï¼ˆå¦‚ï¼šy,y,y,nï¼‰æˆ–æŒ‰Enterè·³è¿‡ï¼š")

        rating = input("> ")
        if rating:
            # ä¿å­˜è¯„åˆ†ç»“æœ
            pass

    print("\nå®¡æ ¸å®Œæˆï¼")

if __name__ == "__main__":
    random_sample_review("data/processed/full_video_atoms.jsonl", 20)
```

---

## ğŸ¯ é˜¶æ®µ1æ€»ç»“

**å®Œæˆæ ‡å‡†**:

```
æ¨¡å—1.1 âœ… é¡¹ç›®åˆå§‹åŒ–
æ¨¡å—1.2 âœ… æ•°æ®æ¨¡å‹å®šä¹‰
æ¨¡å—1.3 âœ… SRTè§£æå™¨
æ¨¡å—1.4 âœ… å·¥å…·å‡½æ•°
æ¨¡å—1.5 âœ… åŸå­åŒ–æç¤ºè¯
æ¨¡å—1.6 âœ… è´¨é‡éªŒè¯å™¨
æ¨¡å—1.7 âœ… é›†æˆæµ‹è¯•
æ¨¡å—1.8 âœ… æç¤ºè¯ä¼˜åŒ–
æ¨¡å—1.9 âœ… å…¨è§†é¢‘æµ‹è¯•
```

**äº¤ä»˜ç‰©**:

```
1. ä»£ç 
   â”œâ”€ parsers/ (SRTè§£æå’Œæ¸…æ´—)
   â”œâ”€ atomizers/ (åŸå­åŒ–å’ŒéªŒè¯)
   â”œâ”€ models/ (æ•°æ®æ¨¡å‹)
   â”œâ”€ utils/ (å·¥å…·å‡½æ•°)
   â”œâ”€ tests/ (æµ‹è¯•è„šæœ¬)
   â”œâ”€ scripts/ (åˆ†æå’Œå¤„ç†è„šæœ¬)
   â”œâ”€ prompts/ (æç¤ºè¯ç‰ˆæœ¬)
   â””â”€ config.py

2. æ•°æ®
   â”œâ”€ test_10min_atoms.jsonl (10åˆ†é’ŸåŸå­æ•°æ®)
   â”œâ”€ full_video_atoms.jsonl (å®Œæ•´è§†é¢‘åŸå­æ•°æ®)
   â”œâ”€ validation_report.json (è´¨é‡æŠ¥å‘Š)
   â””â”€ api_stats.json (æˆæœ¬ç»Ÿè®¡)

3. æ–‡æ¡£
   â”œâ”€ è´¨é‡è¯„åˆ†æŠ¥å‘Š
   â”œâ”€ APIæˆæœ¬ç»Ÿè®¡
   â”œâ”€ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
   â””â”€ äººå·¥å®¡æ ¸ç»“æœ
```

**å…³é”®æŒ‡æ ‡**:

```
âœ… åŸå­åŒ–å‡†ç¡®ç‡: >85%
âœ… æ—¶é—´è¦†ç›–ç‡: >90%
âœ… APIæˆæœ¬: <$60/2å°æ—¶è§†é¢‘
âœ… å¤„ç†æ—¶é—´: <40åˆ†é’Ÿ/2å°æ—¶è§†é¢‘
âœ… è´¨é‡è¯„åˆ†: Bæˆ–ä»¥ä¸Š
âœ… å®Œæ•´ç‰‡æ®µè¯†åˆ«: 5-15ä¸ª/2å°æ—¶è§†é¢‘
```

**é£é™©ç¼“è§£**:

```
âœ… æç¤ºè¯è¿­ä»£æœºåˆ¶å·²å»ºç«‹
âœ… è´¨é‡éªŒè¯è‡ªåŠ¨åŒ–å®Œæˆ
âœ… æˆæœ¬æ§åˆ¶åœ¨é¢„ç®—å†…
âœ… å¤„ç†æ—¶é—´å¯æ¥å—
âœ… å¯æ‰©å±•æ€§å·²éªŒè¯
```

---

## ğŸš€ è¿›å…¥é˜¶æ®µ2çš„æ¡ä»¶

åªæœ‰å½“ä»¥ä¸‹æ‰€æœ‰æ¡ä»¶æ»¡è¶³æ—¶ï¼Œæ‰èƒ½è¿›å…¥é˜¶æ®µ2ï¼š

```
â–¡ 10åˆ†é’Ÿæµ‹è¯•è´¨é‡è¯„åˆ† â‰¥ B
â–¡ å®Œæ•´è§†é¢‘è´¨é‡è¯„åˆ† â‰¥ B
â–¡ APIæˆæœ¬ < $60/2å°æ—¶
â–¡ äººå·¥æŠ½æ ·å‡†ç¡®ç‡ > 85%
â–¡ æ‰€æœ‰æµ‹è¯•è„šæœ¬é€šè¿‡
â–¡ ä»£ç æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶
```

---

## ğŸ“‹ é˜¶æ®µ2é¢„å‘Š

éªŒæ”¶é€šè¿‡åï¼Œè¿›å…¥é˜¶æ®µ2ï¼š**è¯­ä¹‰åˆ†æå±‚**

```
é˜¶æ®µ2ï¼šè¯­ä¹‰åˆ†æå±‚ï¼ˆ5-7å¤©ï¼‰

æ¨¡å—2.1: ä¸»é¢˜åˆ†æå™¨ï¼ˆ1å¤©ï¼‰
  - è¯†åˆ«æ¯ä¸ªåŸå­çš„ä¸»é¢˜æ ‡ç­¾
  - æå–å…³é”®å®ä½“ï¼ˆäººç‰©ã€åœ°ç‚¹ã€äº‹ä»¶ï¼‰

æ¨¡å—2.2: æƒ…æ„Ÿåˆ†æå™¨ï¼ˆ1å¤©ï¼‰
  - æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£é¢/ä¸­æ€§/è´Ÿé¢ï¼‰
  - æƒ…æ„Ÿå¼ºåº¦

æ¨¡å—2.3: ä»·å€¼è¯„ä¼°å™¨ï¼ˆ1å¤©ï¼‰
  - å†…å®¹ä»·å€¼ï¼ˆæ•™è‚²/å¨±ä¹/äº‰è®®ï¼‰
  - é‡è¦æ€§æ‰“åˆ†

æ¨¡å—2.4: å‘é‡åŒ–ï¼ˆ1å¤©ï¼‰
  - OpenAI embeddingsç”Ÿæˆ
  - æ‰¹é‡å¤„ç†ä¼˜åŒ–

æ¨¡å—2.5: å‘é‡ç´¢å¼•ï¼ˆ1å¤©ï¼‰
  - Chromadbé›†æˆ
  - è¯­ä¹‰æœç´¢æµ‹è¯•

æ¨¡å—2.6: è¯­ä¹‰æœç´¢ï¼ˆ1å¤©ï¼‰
  - è·¨åŸå­æœç´¢
  - ç›¸ä¼¼åº¦è®¡ç®—

æ¨¡å—2.7: ç›¸å…³æ€§è®¡ç®—ï¼ˆåŠå¤©ï¼‰
  - åŸå­é—´å…³è”
  - ä¸»é¢˜èšç±»

æ¨¡å—2.8: å®Œæ•´å¤„ç†æµæ°´çº¿ï¼ˆåŠå¤©ï¼‰
  - ç«¯åˆ°ç«¯é›†æˆ
  - æ€§èƒ½ä¼˜åŒ–
```

---

**å½“å‰çŠ¶æ€**: é˜¶æ®µ1è·¯çº¿å›¾å®Œæ•´åˆ¶å®šå®Œæ¯•

**ä¸‹ä¸€æ­¥**: ç­‰å¾…ä½ çš„æŒ‡ç¤ºï¼Œå¼€å§‹å®æ–½æˆ–è°ƒæ•´è·¯çº¿å›¾
